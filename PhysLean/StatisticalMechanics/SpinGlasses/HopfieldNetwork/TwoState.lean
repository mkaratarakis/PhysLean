
import Mathlib.LinearAlgebra.Matrix.Symmetric
import Mathlib.Data.Matrix.Reflection
import Mathlib.Data.Vector.Defs
import Init.Data.Vector.Lemmas
import PhysLean.StatisticalMechanics.SpinGlasses.HopfieldNetwork.aux
import PhysLean.StatisticalMechanics.SpinGlasses.HopfieldNetwork.NeuralNetwork
import PhysLean.Thermodynamics.Temperature.Basic
import PhysLean.StatisticalMechanics.CanonicalEnsemble.TwoState

import Mathlib.Probability.Kernel.Invariance
import Mathlib.Analysis.SpecialFunctions.Exp

import Mathlib.Topology.Basic
import Mathlib.Topology.Instances.Real.Lemmas

import Mathlib

/-!
# Two-state Hopfield networks: Gibbs update and zero-temperature limit

This file builds a general interface for two-state neural networks, provides
three concrete Hopfield-style instances, develops a one-site Gibbs update
kernel, and proves convergence of this kernel to a deterministic zero-temperature
limit as `Œ≤ ‚Üí ‚àû` (equivalently, `T ‚Üí 0+`).

## Overview

- Abstract typeclass `TwoStateNeuralNetwork` for two-valued activations:
  it exposes distinguished states `œÉ_pos`, `œÉ_neg`, a canonical index `Œ∏0` for the
  single threshold parameter, and order data connecting the numeric embedding `m`
  of the two states (`m œÉ_neg < m œÉ_pos`).

- Three concrete encodings of (symmetric) Hopfield parameters:
  * `SymmetricBinary R U` with œÉ = R and activations in {-1, 1}.
  * `SymmetricSignum R U` with œÉ = Signum (a type-level two-point type).
  * `ZeroOne R U` with œÉ = R and activations in {0, 1}.

- A scale parameter, pushed along a ring hom `f`:
  * `scale f : ‚Ñù` and its ring-generalization `scaleS f : S`.
    These quantify the numeric gap between `œÉ_pos` and `œÉ_neg` in the image of `f`.

- Probabilistic update at positive temperature:
  * `logisticProb x := 1 / (1 + exp(-x))` with basic bounds
    `logisticProb_nonneg` and `logisticProb_le_one`.
  * `probPos f p T s u : ‚Ñù` gives `P(œÉ_u = œÉ_pos)` for one Gibbs update, formed from
    logisticProb with argument `(scale f) * f(local field) * Œ≤(T)`.

- One-site PMF update (and sweeps):
  * `updPos`, `updNeg`: force a single site to `œÉ_pos`/`œÉ_neg`.
  * `gibbsUpdate f p T s u : PMF State` is the one-site Gibbs update.
  * `zeroTempDet p s u` is the deterministic threshold update at `T = 0`.
  * `gibbsSweepAux`, `gibbsSweep`: sequential composition over a list of sites.

- Energy specification abstraction:
  * `EnergySpec` and a simplified `EnergySpec'` bundle together a global energy
    `E` and a local-field `localField` satisfying:
      `f (E p (updPos s u) - E p (updNeg s u))
        = - (scale f) * f (localField p s u)`.
    It follows that:
      `probPos f p T s u = logisticProb (- f(ŒîE) * Œ≤(T))`
    where `ŒîE := E p (updPos s u) - E p (updNeg s u)`.

- Zero-temperature limit:
  * `scale_pos f` shows `scale f > 0` for an injective order-embedding `f`.
  * `zeroTempLimitPMF p s u` is the limiting one-step kernel at `T = 0+`, which:
    - moves deterministically to `updPos` if local field is positive,
    - to `updNeg` if negative,
    - and splits 1/2‚Äì1/2 between them on a tie.
  * Main theorem:
      `gibbs_update_tends_to_zero_temp_limit f hf p s u`
    states the PMF `gibbsUpdate f p (tempOfBeta b) s u` converges (as `b ‚Üí ‚àû`)
    to `zeroTempLimitPMF p s u`, pointwise on states.

## Key definitions and lemmas

- Interfaces and instances:
  * `class TwoStateNeuralNetwork NN`:
    exposes `œÉ_pos`, `œÉ_neg`, `Œ∏0`, and ordering data `m œÉ_neg < m œÉ_pos`.
  * Instances:
    - `instTwoStateSymmetricBinary` for `SymmetricBinary`,
    - `instTwoStateSignum` for `SymmetricSignum`,
    - `instTwoStateZeroOne` for `ZeroOne`.

- Scaling gadgets:
  * `scale f : ‚Ñù`, `scaleS f : S`:
    gap between the numeric images of `œÉ_pos` and `œÉ_neg`.
    Specializations:
      - `scale_binary f = f 2` on `SymmetricBinary`,
      - `scale_zeroOne f = f 1` on `ZeroOne`.

- Gibbs probability and PMFs:
  * `logisticProb` with bounds:
      `logisticProb_nonneg`, `logisticProb_le_one`.
  * `probPos f p T s u`:
      `= logisticProb ((scale f) * f(localField) * Œ≤(T))`.
  * `updPos`, `updNeg`: single-site state updates.
  * `gibbsUpdate f p T s u : PMF State`: one-site Gibbs step.
  * `gibbsSweepAux`, `gibbsSweep`: sequential composition over a list of sites.

- Energy view:
  * `EnergySpec`, `EnergySpec'` and the fundamental relation
      `f (E p (updPos s u) - E p (updNeg s u))
        = - (scale f) * f (localField p s u)`.
  * `EnergySpec.probPos_eq_of_energy`:
      re-express `probPos` via the energy difference `ŒîE`.

- Convergence to zero temperature:
  * `scale_pos f`: positivity of `scale f` under an injective order embedding.
  * `zeroTempLimitPMF p s u : PMF State`: the `T ‚Üí 0+` limit kernel.
  * Pointwise convergence on the only two reachable states:
      - `gibbs_update_tends_to_zero_temp_limit_apply_updPos`
      - `gibbs_update_tends_to_zero_temp_limit_apply_updNeg`
    and zero limit on any other target state
      - `gibbs_update_tends_to_zero_temp_limit_apply_other`.
  * Main PMF convergence:
      `gibbs_update_tends_to_zero_temp_limit f hf p s u`.

## Typeclass and notation prerequisites

- Base field and order:
  `[Field R] [LinearOrder R] [IsStrictOrderedRing R]`.
- Sites:
  `[DecidableEq U] [Fintype U] [Nonempty U]` for finite networks and
  decidable equality on sites.
- Embeddings for the scale and probabilities:
  - For `scale` and `probPos` we use a typeclass-driven `f` that is simultaneously
    a ring hom (`[RingHomClass F R ‚Ñù]`) and (when needed for convergence)
    an order embedding (`[OrderHomClass F R ‚Ñù]`) with `Function.Injective f`.

- Probability monad:
  uses `PMF` from Mathlib. The constructions are purely discrete.

## Design notes

- The class `TwoStateNeuralNetwork` abstracts the parts of a network used by a
  two-site threshold update: a canonical scalar threshold index `Œ∏0`, the result
  of `fact` at or above threshold (`œÉ_pos`) and strictly below (`œÉ_neg`), and
  numeric ordering `m œÉ_neg < m œÉ_pos`.
- The concrete Hopfield instances share the same adjacency and `Œ∫2 = 1` setup,
  but differ in the activation alphabet and decoding map `m`.
- The scaling `scale f` is a thin adapter that makes formulas uniform across
  different encodings, so that Gibbs updates depending on `f(local field)` and
  `Œ≤(T)` can be stated once for all `NN`.

## Usage

- To run one Gibbs update at site `u`:
  ```
  gibbsUpdate f p T s u : PMF _
  ```
- To sweep a list of sites in order:
  ```
  gibbsSweep order p T f s0 : PMF _
  ```
- If you can provide an `EnergySpec`, then:
  ```
  probPos f p T s u = logisticProb (- f(ŒîE) * Œ≤(T))
  ```
  where `ŒîE = E p (updPos s u) - E p (updNeg s u)`.

- The zero-temperature limit theorem applies once you supply an `f` that is both
  a ring hom and an injective order embedding (via the corresponding typeclasses).

## TODO

- Finish the (commented) section proving reversibility and invariance of the
  random-scan Gibbs kernel w.r.t. the Boltzmann distribution, after adding a
  finite enumeration of states and the necessary summation lemmas.
- Provide convenience embeddings `f : R ‚Üí+* ‚Ñù` for common `R` (e.g. `R = ‚Ñù`).

-/

open Finset Matrix NeuralNetwork State Constants Temperature Filter Topology
open scoped ENNReal NNReal BigOperators
open NeuralNetwork

--variable {R U œÉ : Type}
--variable {R U œÉ : Type*}
universe uR uU uœÉ

-- (Optional) you can also parametrize earlier variables with these universes if desired:
variable {R : Type uR} {U : Type uU} {œÉ : Type uœÉ}

/-- A minimal two-point activation alphabet.

This class specifies:
- `œÉ_pos`: the distinguished ‚Äúpositive‚Äù activation,
- `œÉ_neg`: the distinguished ‚Äúnegative‚Äù activation,
- `embed`: a numeric embedding `œÉ ‚Üí R` used to interpret activations in the ambient ring `R`.
-/
class TwoPointActivation (R : Type uR) (œÉ : Type uœÉ) where
  /-- Distinguished ‚Äúpositive‚Äù activation state. -/
  œÉ_pos : œÉ
  /-- Distinguished ‚Äúnegative‚Äù activation state. -/
  œÉ_neg : œÉ
  /-- Numeric embedding of activation states into the ambient ring `R`. -/
  embed : œÉ ‚Üí R

/-- Scale between the two distinguished activations in `œÉ`, computed in `R` via the embedding.
It is defined as `embed œÉ_pos - embed œÉ_neg`. -/
@[simp] def twoPointScale {R œÉ} [Sub R] [TwoPointActivation R œÉ] : R :=
  TwoPointActivation.embed (R:=R) (œÉ:=œÉ) (TwoPointActivation.œÉ_pos (R:=R) (œÉ:=œÉ)) -
    TwoPointActivation.embed (R:=R) (œÉ:=œÉ) (TwoPointActivation.œÉ_neg (R:=R) (œÉ:=œÉ))

/-- Two‚Äìstate neural networks (abstract interface).

This exposes:
- `œÉ_pos`, `œÉ_neg`: the two distinguished activation states,
- `Œ∏0`: a canonical index into the `Œ∫2`-vector of thresholds extracting the scalar threshold,
- facts that `fact` returns `œÉ_pos` at or above `Œ∏0`, and `œÉ_neg` strictly below,
- that both `œÉ_pos` and `œÉ_neg` satisfy `pact`,
- and an order gap on the numeric embedding `m` (`m œÉ_neg < m œÉ_pos`). -/
class TwoStateNeuralNetwork {R U œÉ}
  [Field R] [LinearOrder R] [IsStrictOrderedRing R]
  (NN : NeuralNetwork R U œÉ) where
  /-- Distinguished ‚Äúpositive‚Äù activation state. -/
  œÉ_pos : œÉ
  /-- Distinguished ‚Äúnegative‚Äù activation state. -/
  œÉ_neg : œÉ
  /-- Proof that the two distinguished activation states are distinct. -/
  h_pos_ne_neg : œÉ_pos ‚â† œÉ_neg
  /-- Canonical index in `Œ∫2 u` selecting the scalar threshold used by `fact`. -/
  Œ∏0 : ‚àÄ u : U, Fin (NN.Œ∫2 u)
  /-- At or above threshold `Œ∏0 u`, `fact` returns `œÉ_pos`. -/
  h_fact_pos :
    ‚àÄ u (œÉcur : œÉ) (net : R) (Œ∏ : Vector R (NN.Œ∫2 u)),
      (Œ∏.get (Œ∏0 u)) ‚â§ net ‚Üí NN.fact u œÉcur net Œ∏ = œÉ_pos
  /-- Strictly below threshold `Œ∏0 u`, `fact` returns `œÉ_neg`. -/
  h_fact_neg :
    ‚àÄ u (œÉcur : œÉ) (net : R) (Œ∏ : Vector R (NN.Œ∫2 u)),
      net < (Œ∏.get (Œ∏0 u)) ‚Üí NN.fact u œÉcur net Œ∏ = œÉ_neg
  /-- `œÉ_pos` satisfies the activation predicate `pact`. -/
  h_pact_pos : NN.pact œÉ_pos
  /-- `œÉ_neg` satisfies the activation predicate `pact`. -/
  h_pact_neg : NN.pact œÉ_neg
  /-- Numeric embedding separates the two states: `m œÉ_neg < m œÉ_pos`. -/
  m_order : NN.m œÉ_neg < NN.m œÉ_pos

namespace TwoState
variable {R U œÉ : Type}
variable [Field R] [LinearOrder R] [IsStrictOrderedRing R]
--variable [DecidableEq U] [Fintype U] [Nonempty U]

/-! Concrete network families (three encodings). -/

/-- Helper canonical index for all concrete networks with Œ∫2 = 1. -/
@[inline] def fin0 : Fin 1 := ‚ü®0, by decide‚ü©

/-- Standard symmetric Hopfield parameters with activations in {-1,1} (œÉ = R). -/
def SymmetricBinary (R U : Type) [Field R] [LinearOrder R]
    [DecidableEq U] [Fintype U] [Nonempty U] : NeuralNetwork R U R :=
{ Adj := fun u v => u ‚â† v
  Ui := Set.univ
  Uo := Set.univ
  Uh := ‚àÖ
  hUi := by simp
  hUo := by simp
  hU := by simp
  hhio := by simp
  Œ∫1 := fun _ => 1
  Œ∫2 := fun _ => 1
  pw := fun W => W.IsSymm ‚àß ‚àÄ u, W u u = 0
  pact := fun a => a = 1 ‚à® a = -1
  fnet := fun u row pred _ => ‚àë v, if v ‚â† u then row v * pred v else 0
  fact := fun _ _ net Œ∏ => if Œ∏.get fin0 ‚â§ net then 1 else -1
  fout := fun _ a => a
  m := id
  hpact := by
    classical
    intro W _ _ _ Œ∏ cur hcur u
    by_cases hth :
        (Œ∏ u).get fin0 ‚â§ ‚àë v, if v ‚â† u then W u v * cur v else 0
    ¬∑ simp [pact, fact, fnet, hth]; aesop
    ¬∑ simp [pact, fact, fnet, hth]; aesop }

/-- Type level two-value signum variant. -/
inductive Signum | pos | neg deriving DecidableEq

instance : Fintype Signum where
  elems := {Signum.pos, Signum.neg}
  complete := by intro x; cases x <;> simp

/-- Symmetric Hopfield parameters with œÉ = Signum. -/
def SymmetricSignum (R U : Type) [Field R] [LinearOrder R]
    [DecidableEq U] [Fintype U] [Nonempty U] : NeuralNetwork R U Signum :=
{ Adj := fun u v => u ‚â† v
  Ui := Set.univ
  Uo := Set.univ
  Uh := ‚àÖ
  hUi := by simp
  hUo := by simp
  hU := by simp
  hhio := by simp
  Œ∫1 := fun _ => 1
  Œ∫2 := fun _ => 1
  pw := fun W => W.IsSymm ‚àß ‚àÄ u, W u u = 0
  fnet := fun u row pred _ => ‚àë v, if v ‚â† u then row v * pred v else 0
  pact := fun _ => True
  fact := fun _ _ net Œ∏ => if Œ∏.get fin0 ‚â§ net then Signum.pos else Signum.neg
  fout := fun _ s => match s with | .pos => (1 : R) | .neg => (-1 : R)
  m := fun s => match s with | .pos => (1 : R) | .neg => (-1 : R)
  hpact := by intro; simp }

/-- Zero / one network (œÉ ‚àà {0,1}). -/
def ZeroOne (R U : Type) [Field R] [LinearOrder R]
    [DecidableEq U] [Fintype U] [Nonempty U] : NeuralNetwork R U R :=
{ (SymmetricBinary R U) with
  pact := fun a => a = 0 ‚à® a = 1
  fact := fun _ _ net Œ∏ => if Œ∏.get fin0 ‚â§ net then 1 else 0
  hpact := by
    classical
    intro W _ _ œÉ Œ∏ cur hcur u
    by_cases hth :
        (Œ∏ u).get fin0 ‚â§ ‚àë v, if v ‚â† u then W u v * cur v else 0
    ¬∑ simp [SymmetricBinary, pact, fact, hth]; aesop
    ¬∑ simp [SymmetricBinary, pact, fact, hth]; aesop }

variable [DecidableEq U] [Fintype U] [Nonempty U]

instance instTwoStateSymmetricBinary :
  TwoStateNeuralNetwork (SymmetricBinary R U) where
  œÉ_pos := (1 : R); œÉ_neg := (-1 : R)
  h_pos_ne_neg := by
    have h0 : (0 : R) < 1 := zero_lt_one
    have hneg : (-1 : R) < 0 := by simp
    have hlt : (-1 : R) < 1 := hneg.trans h0
    exact (ne_of_lt hlt).symm
  Œ∏0 := fun _ => fin0
  h_fact_pos := by
    intro u œÉcur net Œ∏ hle; simp [SymmetricBinary, hle]
  h_fact_neg := by
    intro u œÉcur net Œ∏ hlt
    have : ¬¨ Œ∏.get fin0 ‚â§ net := not_le.mpr hlt
    simp [SymmetricBinary, this]
  h_pact_pos := by left; rfl
  h_pact_neg := by right; rfl
  m_order := by
    have h0 : (0 : R) < 1 := zero_lt_one
    have hneg : (-1 : R) < 0 := by simp
    exact hneg.trans h0

instance instTwoStateSignum :
  TwoStateNeuralNetwork (SymmetricSignum R U) where
  œÉ_pos := Signum.pos; œÉ_neg := Signum.neg
  h_pos_ne_neg := by intro h; cases h
  Œ∏0 := fun _ => fin0
  h_fact_pos := by
    intro u œÉcur net Œ∏ hn
    change (if Œ∏.get fin0 ‚â§ net then Signum.pos else Signum.neg) = Signum.pos
    simp [hn]
  h_fact_neg := by
    intro u œÉcur net Œ∏ hlt
    change (if Œ∏.get fin0 ‚â§ net then Signum.pos else Signum.neg) = Signum.neg
    have : ¬¨ Œ∏.get fin0 ‚â§ net := not_le.mpr hlt
    simp [this]
  h_pact_pos := by trivial
  h_pact_neg := by trivial
  m_order := by
    -- `m` maps pos ‚Ü¶ 1, neg ‚Ü¶ -1
    have h0 : (0 : R) < 1 := zero_lt_one
    have hneg : (-1 : R) < 0 := by simp
    simp [SymmetricSignum]

instance instTwoStateZeroOne :
  TwoStateNeuralNetwork (ZeroOne R U) where
  œÉ_pos := (1 : R); œÉ_neg := (0 : R)
  h_pos_ne_neg := one_ne_zero
  Œ∏0 := fun _ => fin0
  h_fact_pos := by
    intro u œÉcur net Œ∏ hn
    change (if Œ∏.get fin0 ‚â§ net then (1 : R) else 0) = 1
    simp [hn]
  h_fact_neg := by
    intro u œÉcur net Œ∏ hlt
    change (if Œ∏.get fin0 ‚â§ net then (1 : R) else 0) = 0
    have : ¬¨ Œ∏.get fin0 ‚â§ net := not_le.mpr hlt
    simp [this]
  h_pact_pos := by right; rfl
  h_pact_neg := by left; rfl
  m_order := by
    -- m = id, so goal is 0 < 1
    simp [ZeroOne, SymmetricBinary]

/-- Scale between numeric embeddings of the two states (pushed along f). -/
noncomputable def scale
    {F} [FunLike F R ‚Ñù]
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (f : F) : ‚Ñù :=
  f (NN.m (TwoStateNeuralNetwork.œÉ_pos (NN:=NN))) -
    f (NN.m (TwoStateNeuralNetwork.œÉ_neg (NN:=NN)))

/-- Generalized scale in an arbitrary target ring S. -/
noncomputable def scaleS
    {S} [Ring S] {F} [FunLike F R S]
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN] (f : F) : S :=
  f (NN.m (TwoStateNeuralNetwork.œÉ_pos (NN:=NN))) -
    f (NN.m (TwoStateNeuralNetwork.œÉ_neg (NN:=NN)))

omit [DecidableEq U] [Fintype U] [Nonempty U] in
@[simp] lemma scaleS_apply_‚Ñù
    {F} [FunLike F R ‚Ñù]
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN] (f : F) :
    scaleS (NN:=NN) (f:=f) = scale (NN:=NN) (f:=f) := rfl

@[simp] lemma scale_binary (f : R ‚Üí+* ‚Ñù) :
    scale (R:=R) (U:=U) (œÉ:=R) (NN:=SymmetricBinary R U) (f:=f) = f 2 := by
  -- œÉ_pos = 1, œÉ_neg = -1, m = id
  unfold scale
  simp [instTwoStateSymmetricBinary, SymmetricBinary, sub_neg_eq_add, one_add_one_eq_two]
  rw [@map_ofNat]

@[simp] lemma scale_zeroOne (f : R ‚Üí+* ‚Ñù) :
    scale (R:=R) (U:=U) (œÉ:=R) (NN:=ZeroOne R U) (f:=f) = f 1 := by
  -- œÉ_pos = 1, œÉ_neg = 0, m = id
  unfold scale
  simp [instTwoStateZeroOne, ZeroOne, SymmetricBinary]

/-- Logistic function used for Gibbs probabilities. -/
noncomputable def logisticProb (x : ‚Ñù) : ‚Ñù := 1 / (1 + Real.exp (-x))

lemma logisticProb_nonneg (x : ‚Ñù) : 0 ‚â§ logisticProb x := by
  unfold logisticProb
  have hx : 0 < Real.exp (-x) := Real.exp_pos _
  have hden : 0 < 1 + Real.exp (-x) := by linarith
  exact div_nonneg zero_le_one hden.le

lemma logisticProb_le_one (x : ‚Ñù) : logisticProb x ‚â§ 1 := by
  unfold logisticProb
  have hx : 0 < Real.exp (-x) := Real.exp_pos _
  have hden : 0 < 1 + Real.exp (-x) := by linarith
  have : 1 ‚â§ 1 + Real.exp (-x) := by
    linarith
  simpa using (div_le_one hden).mpr this

/-- Probability P(œÉ_u = œÉ_pos) for one Gibbs update. -/
noncomputable def probPos
    {F} [FunLike F R ‚Ñù]
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (f : F) (p : Params NN) (T : Temperature) (s : NN.State) (u : U) : ‚Ñù :=
  let L := (s.net p u) - (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)
  let Œ∫ := scale (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f)
  logisticProb (Œ∫ * (f L) * (Œ≤ T))

omit [DecidableEq U] [Fintype U] [Nonempty U] in
lemma probPos_nonneg
    {F} [FunLike F R ‚Ñù]
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (f : F) (p : Params NN) (T : Temperature) (s : NN.State) (u : U) :
    0 ‚â§ probPos (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) f p T s u := by
  unfold probPos; apply logisticProb_nonneg

omit [DecidableEq U] [Fintype U] [Nonempty U] in
lemma probPos_le_one
    {F} [FunLike F R ‚Ñù]
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (f : F) (p : Params NN) (T : Temperature) (s : NN.State) (u : U) :
    probPos (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) f p T s u ‚â§ 1 := by
  unfold probPos; apply logisticProb_le_one

/-- Force neuron u to œÉ_pos. -/
def updPos {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (s : NN.State) (u : U) : NN.State :=
{ act := Function.update s.act u (TwoStateNeuralNetwork.œÉ_pos (NN:=NN))
, hp := by
    intro v
    by_cases h : v = u
    ¬∑ subst h; simpa using TwoStateNeuralNetwork.h_pact_pos (NN:=NN)
    ¬∑ simpa [Function.update, h] using s.hp v }

/-- Force neuron u to œÉ_neg. -/
def updNeg {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (s : NN.State) (u : U) : NN.State :=
{ act := Function.update s.act u (TwoStateNeuralNetwork.œÉ_neg (NN:=NN))
, hp := by
    intro v
    by_cases h : v = u
    ¬∑ subst h; simpa using TwoStateNeuralNetwork.h_pact_neg (NN:=NN)
    ¬∑ simpa [Function.update, h] using s.hp v }

/-- One‚Äìsite Gibbs update kernel (PMF). -/
noncomputable def gibbsUpdate
    {F} [FunLike F R ‚Ñù]
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (f : F) (p : Params NN) (T : Temperature) (s : NN.State) (u : U) :
    PMF (NN.State) := by
  classical
  let pPos := probPos (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) f p T s u
  let pPosE := ENNReal.ofReal pPos
  have h_le : pPosE ‚â§ 1 := by
    rw [ENNReal.ofReal_le_one]
    exact probPos_le_one (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) f p T s u
  exact
    PMF.bernoulli pPosE h_le >>= fun b =>
      if b then PMF.pure (updPos (s:=s) (u:=u)) else PMF.pure (updNeg (s:=s) (u:=u))

/-- Zero‚Äìtemperature deterministic (threshold) update at site u.
    (Adjusted to avoid unused variable warning in the Prop-based `if`.) -/
def zeroTempDet
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (p : Params NN) (s : NN.State) (u : U) : NN.State :=
  let net := s.net p u
  let Œ∏ := (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)
  if h : Œ∏ ‚â§ net then
    (have _ := h; updPos (s:=s) (u:=u))
  else
    (have _ := h; updNeg (s:=s) (u:=u))

/-- Gibbs sweep auxiliary function. -/
noncomputable def gibbsSweepAux
    {F} [FunLike F R ‚Ñù]
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (f : F) (p : Params NN) (T : Temperature) :
    List U ‚Üí NN.State ‚Üí PMF NN.State
  | [],       s => PMF.pure s
  | u :: us, s =>
      gibbsUpdate (NN:=NN) f p T s u >>= fun s' =>
        gibbsSweepAux f p T us s'

omit [Fintype U] [Nonempty U] in
@[simp] lemma gibbsSweepAux_nil
    {F} [FunLike F R ‚Ñù]
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (f : F) (p : Params NN) (T : Temperature) (s : NN.State) :
    gibbsSweepAux (NN:=NN) f p T [] s = PMF.pure s := rfl

omit [Fintype U] [Nonempty U] in
@[simp] lemma gibbsSweepAux_cons
    {F} [FunLike F R ‚Ñù]
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (f : F) (p : Params NN) (T : Temperature) (u : U) (us : List U) (s : NN.State) :
    gibbsSweepAux (NN:=NN) f p T (u :: us) s =
      gibbsUpdate (NN:=NN) f p T s u >>= fun s' =>
        gibbsSweepAux (NN:=NN) f p T us s' := rfl

/-- Sequential Gibbs sweep over a list of sites, head applied first. -/
noncomputable def gibbsSweep
    {F} [FunLike F R ‚Ñù]
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (order : List U) (p : Params NN) (T : Temperature) (f : F)
    (s0 : NN.State) : PMF NN.State :=
  gibbsSweepAux (NN:=NN) f p T order s0

omit [Fintype U] [Nonempty U] in
@[simp] lemma gibbsSweep_nil
    {F} [FunLike F R ‚Ñù]
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (p : Params NN) (T : Temperature) (f : F) (s0 : NN.State) :
    gibbsSweep (NN:=NN) ([] : List U) p T f s0 = PMF.pure s0 := rfl

omit [Fintype U] [Nonempty U] in
lemma gibbsSweep_cons
    {F} [FunLike F R ‚Ñù]
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (u : U) (us : List U) (p : Params NN) (T : Temperature) (f : F) (s0 : NN.State) :
    gibbsSweep (NN:=NN) (u :: us) p T f s0 =
      (gibbsUpdate (NN:=NN) f p T s0 u) >>= fun s =>
        gibbsSweep (NN:=NN) us p T f s := rfl

@[simp] lemma probPos_nonneg_apply_binary
    (f : R ‚Üí+* ‚Ñù) (p : Params (SymmetricBinary R U)) (T : Temperature)
    (s : (SymmetricBinary R U).State) (u : U) :
    0 ‚â§ probPos (R:=R) (U:=U) (œÉ:=R) (NN:=SymmetricBinary R U) f p T s u :=
  probPos_nonneg (R:=R) (U:=U) (œÉ:=R) (NN:=SymmetricBinary R U) f p T s u

@[simp] lemma probPos_le_one_apply_binary
    (f : R ‚Üí+* ‚Ñù) (p : Params (SymmetricBinary R U)) (T : Temperature)
    (s : (SymmetricBinary R U).State) (u : U) :
    probPos (R:=R) (U:=U) (œÉ:=R) (NN:=SymmetricBinary R U) f p T s u ‚â§ 1 :=
  probPos_le_one (R:=R) (U:=U) (œÉ:=R) (NN:=SymmetricBinary R U) f p T s u

/-- **Energy specification bundling a global energy and a local field**.

This abstracts the thermodynamic view:
- `E p s` is the global energy of state `s` under parameters `p`;
- `localField p s u` is the local field at site `u` in state `s`.
-  The specification `localField_spec` connects the local field to the
  network primitives, and `flip_energy_relation` states the fundamental
  relation between energy differences and local fields.
Together these properties connect energy differences
to local fields and underpin the Gibbs/zero‚Äìtemperature analysis. -/
structure EnergySpec
    {R U œÉ} [Field R] [LinearOrder R] [IsStrictOrderedRing R]
    [DecidableEq U]
    (NN : NeuralNetwork R U œÉ) [TwoStateNeuralNetwork NN] where
  /-- Global energy function `E p s`. -/
  E : Params NN ‚Üí NN.State ‚Üí R
  /-- Local field `L = localField p s u` at site `u`. -/
  localField : Params NN ‚Üí NN.State ‚Üí U ‚Üí R
  /-- Specification tying the abstract `localField` to the network primitives:
      `localField p s u = s.net p u - (p.Œ∏ u).get (Œ∏0 u)`. -/
  localField_spec :
    ‚àÄ (p : Params NN) (s : NN.State) (u : U),
      localField p s u =
        (s.net p u) - (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)
  /-- Fundamental flip‚Äìenergy relation: the energy difference between the
      `updPos` and `updNeg` flips at `u` equals `- scale f * f(localField p s u)`,
      when pushed along a ring hom `f : R ‚Üí+* ‚Ñù`. -/
  flip_energy_relation :
    ‚àÄ (f : R ‚Üí+* ‚Ñù)
      (p : Params NN) (s : NN.State) (u : U),
      let sPos := updPos (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (s:=s) (u:=u)
      let sNeg := updNeg (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (s:=s) (u:=u)
      f (E p sPos - E p sNeg) =
        - (scale (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f)) *
          f (localField p s u)

/-- A simplified energy specification carrying the same data as `EnergySpec`,
with the flip relation stated using inlined `updPos`/`updNeg`. -/
structure EnergySpec'
    {R U œÉ} [Field R] [LinearOrder R] [IsStrictOrderedRing R]
    [DecidableEq U]
    (NN : NeuralNetwork R U œÉ) [TwoStateNeuralNetwork NN] where
  /-- Global energy function `E p s`. -/
  E : Params NN ‚Üí NN.State ‚Üí R
  /-- Local field `L = localField p s u` at site `u`. -/
  localField : Params NN ‚Üí NN.State ‚Üí U ‚Üí R
  /-- Specification tying `localField` to the network primitives:
      `localField p s u = s.net p u - (p.Œ∏ u).get (Œ∏0 u)`. -/
  localField_spec :
    ‚àÄ (p : Params NN) (s : NN.State) (u : U),
      localField p s u =
        (s.net p u) - (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)
  /-- Fundamental flip‚Äìenergy relation pushed along a ring hom `f : R ‚Üí+* ‚Ñù`:
      `f (E p (updPos s u) - E p (updNeg s u))
        = - scale f * f (localField p s u)`. -/
  flip_energy_relation :
    ‚àÄ (f : R ‚Üí+* ‚Ñù)
      (p : Params NN) (s : NN.State) (u : U),
      f (E p (updPos (NN:=NN) s u) - E p (updNeg (NN:=NN) s u)) =
        - (scale (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f)) *
          f (localField p s u)

namespace EnergySpec
variable {NN : NeuralNetwork R U œÉ}
variable [TwoStateNeuralNetwork NN]

omit [Fintype U] [Nonempty U] in
lemma flip_energy_rel'
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù]
    (ES : TwoState.EnergySpec (NN:=NN)) (f : F)
    (p : Params NN) (s : NN.State) (u : U) :
    f (ES.E p (updPos (NN:=NN) s u) - ES.E p (updNeg (NN:=NN) s u)) =
      - (scale (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f)) *
        f ((s.net p u) - (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)) := by
  -- we build a bundled ring hom from f; its coercion is definitionally f
  let f_hom : R ‚Üí+* ‚Ñù :=
  { toMonoidHom :=
    { toFun := f
      map_one' := map_one f
      map_mul' := map_mul f }
    map_zero' := map_zero f
    map_add' := map_add f }
  have h := ES.flip_energy_relation f_hom p s u
  simpa [ES.localField_spec] using h

omit [Fintype U] [Nonempty U] in
lemma probPos_eq_of_energy
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù]
    (ES : EnergySpec (NN:=NN)) (f : F) (p : Params NN) (T : Temperature)
    (s : NN.State) (u : U) :
    probPos (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) f p T s u =
      let sPos := updPos (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (s:=s) (u:=u)
      let sNeg := updNeg (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (s:=s) (u:=u)
      let Œî := f (ES.E p sPos - ES.E p sNeg)
      logisticProb (- Œî * (Œ≤ T)) := by
  classical
  unfold probPos
  have hŒî :=
    ES.flip_energy_rel' (f:=f) p s u
  simp [ES.localField_spec, hŒî, logisticProb,
        mul_comm, mul_left_comm, mul_assoc,
        add_comm, add_left_comm, add_assoc]

end EnergySpec

namespace EnergySpec'
variable {NN : NeuralNetwork R U œÉ}
variable [TwoStateNeuralNetwork NN]

/-- Convert an `EnergySpec` to an `EnergySpec'`. -/
def ofOld
    (ES : TwoState.EnergySpec (NN:=NN)) : EnergySpec' (NN:=NN) :=
{ E := ES.E
, localField := ES.localField
, localField_spec := ES.localField_spec
, flip_energy_relation := by
    intro f p s u
    simpa using (ES.flip_energy_relation f p s u) }

omit [Fintype U] [Nonempty U] in
lemma flip_energy_rel'
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù]
    (ES : EnergySpec' (NN:=NN)) (f : F)
    (p : Params NN) (s : NN.State) (u : U) :
    f (ES.E p (updPos (NN:=NN) s u) - ES.E p (updNeg (NN:=NN) s u)) =
      - (scale (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f)) *
        f ((s.net p u) - (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)) := by
  -- Build a bundled ring hom from f; its coercion is definitionally f
  let f_hom : R ‚Üí+* ‚Ñù :=
  { toMonoidHom :=
    { toFun := f
      map_one' := map_one f
      map_mul' := map_mul f }
    map_zero' := map_zero f
    map_add' := map_add f }
  have h := ES.flip_energy_relation f_hom p s u
  simpa [ES.localField_spec] using h

end EnergySpec'

omit [Fintype U] [Nonempty U] in
lemma EnergySpec.flip_energy_rel''
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (ES : TwoState.EnergySpec (NN:=NN))
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] (f : F)
    (p : Params NN) (s : NN.State) (u : U) :
    f (ES.E p (updPos (NN:=NN) s u) - ES.E p (updNeg (NN:=NN) s u)) =
      - (scale (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f)) *
        f ((s.net p u) - (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)) := by
  classical
  refine (EnergySpec'.flip_energy_rel'
            (EnergySpec'.ofOld (NN:=NN) ES) (f:=f) p s u)

/-! ### Convergence
As Œ≤ ‚Üí ‚àû (i.e., T ‚Üí 0+), the one‚Äìsite Gibbs update PMF converges pointwise to the
zero‚Äìtemperature limit kernel, for any TwoState NN and any order-embedding f. -/

open scoped Topology Filter
open PMF Filter

section Convergence
variable {R U œÉ : Type}
variable [Field R] [LinearOrder R] [IsStrictOrderedRing R]
variable [DecidableEq U] [Fintype U] [Nonempty U]

variable {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]

omit [Field R] [IsStrictOrderedRing R] in
-- strict monotonicity from order-hom + injective
lemma strictMono_of_injective_orderHom
    {F} [FunLike F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f) : StrictMono f :=
  (OrderHomClass.mono f).strictMono_of_injective hf

/-- If `a > 0`, the piecewise {1, 0, 1/2} based on the sign of `a*v` matches that of `v`. -/
lemma piecewise01half_sign_mul_left_pos {a v : ‚Ñù} (ha : 0 < a) :
    (if 0 < a * v then 1 else if a * v < 0 then 0 else (1/2 : ‚Ñù))
    =
    (if 0 < v then 1 else if v < 0 then 0 else (1/2 : ‚Ñù)) := by
  by_cases hvpos : 0 < v
  ¬∑ have : 0 < a * v := Left.mul_pos ha hvpos
    simp [hvpos, this, not_lt.mpr this.le]
  ¬∑ by_cases hvneg : v < 0
    ¬∑ have : a * v < 0 := mul_neg_of_pos_of_neg ha hvneg
      simp [hvpos, hvneg, this, not_lt.mpr this.le]
    ¬∑ have hv0 : v = 0 := le_antisymm (le_of_not_gt hvpos) (le_of_not_gt hvneg)
      simp [hvpos, hvneg, hv0]

/-- If `x < 0` then the {1,0,1/2} piecewise is ‚â§ 0 (it equals 0). -/
private lemma piecewise01half_le_zero_of_neg {x : ‚Ñù} (hx : x < 0) :
    (if 0 < x then 1 else if x < 0 then 0 else (1/2 : ‚Ñù)) ‚â§ 0 := by
  have hnotpos : ¬¨ 0 < x := not_lt.mpr hx.le
  simp [hnotpos, hx]

omit [Fintype U] [Nonempty U] [DecidableEq U] in
/-- Rewrite the 1/0/1/2 piecewise expression by dropping the positive `1/kB` factor
in front of its argument. This aligns the ‚Äúzero-temperature target‚Äù with the
real-limit expression using `c0 := Œ∫ * f L`. -/
lemma sign_piecewise_rewrite_with_c0
    {F} [FunLike F R ‚Ñù]
    (f : F)
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN]
    (L : R) :
    let Œ∫ := scale (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f)
    (if 0 < ((Œ∫ / kB) * (f L)) then 1
     else if ((Œ∫ / kB) * (f L)) < 0 then 0 else (1/2 : ‚Ñù))
    =
    (if 0 < (Œ∫ * (f L)) then 1
     else if (Œ∫ * (f L)) < 0 then 0 else (1/2 : ‚Ñù)) := by
  intro Œ∫
  have ha : 0 < (kB : ‚Ñù)‚Åª¬π := inv_pos.mpr kB_pos
  have hrewrite :
      ((Œ∫ / kB) * (f L)) = (kB : ‚Ñù)‚Åª¬π * (Œ∫ * (f L)) := by
    simp [div_eq_mul_inv, mul_left_comm, mul_assoc]
  have h := piecewise01half_sign_mul_left_pos
              (a := (kB : ‚Ñù)‚Åª¬π) (v := Œ∫ * (f L)) ha
  simpa [hrewrite] using h

omit [IsStrictOrderedRing R] in
/-- Map of a positive (resp. negative) argument remains positive (resp. negative)
under a strictly monotone embedding sending `0 ‚Ü¶ 0`. -/
lemma map_pos_of_pos
    {F} [FunLike F R ‚Ñù] [OrderHomClass F R ‚Ñù] [RingHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f) {x : R} (hx : 0 < x) : 0 < f x := by
  have hsm := strictMono_of_injective_orderHom (R:=R) (f:=f) hf
  simpa [map_zero f] using (hsm hx)

omit [IsStrictOrderedRing R] in
lemma map_neg_of_neg
    {F} [FunLike F R ‚Ñù] [OrderHomClass F R ‚Ñù] [RingHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f) {x : R} (hx : x < 0) : f x < 0 := by
  have hsm := strictMono_of_injective_orderHom (R:=R) (f:=f) hf
  simpa [map_zero f] using (hsm hx)

omit [DecidableEq U] [Fintype U] [Nonempty U] in
/-- Œ∫ := scale between the two numeric states (pushed along f) is positive
    under a strictly monotone embedding and the class `m_order`. -/
lemma scale_pos
    {F} [FunLike F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f)
    {NN : NeuralNetwork R U œÉ} [TwoStateNeuralNetwork NN] :
    0 < scale (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f) := by
  -- TwoStateNeuralNetwork.m_order : m œÉ_neg < m œÉ_pos
  have h := (strictMono_of_injective_orderHom (R:=R) (f:=f) hf)
  have himg :
      f (NN.m (TwoStateNeuralNetwork.œÉ_neg (NN:=NN))) <
        f (NN.m (TwoStateNeuralNetwork.œÉ_pos (NN:=NN))) :=
    h (TwoStateNeuralNetwork.m_order (NN:=NN))
  exact sub_pos.mpr himg

/-- One-step zero-temperature limit kernel (tie -> 1/2 mixture of updPos/updNeg). -/
noncomputable def zeroTempLimitPMF
    (p : Params NN) (s : NN.State) (u : U) : PMF NN.State :=
  let net := s.net p u
  let Œ∏ := (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)
  if h : Œ∏ < net then
    PMF.pure (updPos (s:=s) (u:=u))
  else if h' : net < Œ∏ then
    PMF.pure (updNeg (s:=s) (u:=u))
  else
    let pHalf : ‚Ñù‚â•0‚àû := ENNReal.ofReal (1/2)
    have hp : pHalf ‚â§ 1 := by
      simpa [pHalf] using
        (ENNReal.ofReal_le_one.mpr (by norm_num : (1/2 : ‚Ñù) ‚â§ 1))
    PMF.bernoulli pHalf hp >>= fun b =>
      if b then PMF.pure (updPos (s:=s) (u:=u)) else PMF.pure (updNeg (s:=s) (u:=u))

omit [Fintype U] [Nonempty U] in
/-- Helper: the two updated states differ. -/
private lemma updPos_ne_updNeg (s : NN.State) (u : U) :
    updPos (s:=s) (u:=u) ‚â† updNeg (s:=s) (u:=u) := by
  intro h
  have := congrArg (fun st => st.act u) h
  simp [updPos, updNeg, Function.update, TwoStateNeuralNetwork.h_pos_ne_neg] at this

/-
  General limit lemmas for reals, used to analyze the zero-temperature limit.
  These are independent of the neural-network context (mathlib-ready).
-/
open Real Filter Topology Monotone

/-- Multiplication by a positive constant maps `atTop` to `atTop`. -/
lemma tendsto_mul_const_atTop_atTop_of_pos {c : ‚Ñù} (hc : 0 < c) :
    Tendsto (fun x : ‚Ñù => c * x) atTop atTop := by
  refine (Filter.tendsto_atTop_atTop).2 ?_
  intro M
  refine ‚ü®M / c, ?_‚ü©
  intro x hx
  exact (div_le_iff‚ÇÄ' hc).mp hx

/-- Multiplication by a negative constant maps `atTop` to `atBot`. -/
lemma tendsto_mul_const_atTop_atBot_of_neg {c : ‚Ñù} (hc : c < 0) :
    Tendsto (fun x : ‚Ñù => c * x) atTop atBot := by
  refine (Filter.tendsto_atTop_atBot).2 ?_
  intro M
  refine ‚ü®M / c, ?_‚ü©
  intro x hx
  exact (div_le_iff_of_neg' hc).mp hx

/-- As `x ‚Üí +‚àû`, `logisticProb x ‚Üí 1`. -/
lemma logisticProb_tendsto_atTop :
    Tendsto logisticProb atTop (ùìù (1 : ‚Ñù)) := by
  -- logisticProb x = 1/(1 + exp(-x)); as x‚Üí+‚àû, -x‚Üí-‚àû, so exp(-x)‚Üí0, then 1/(1+r)‚Üí1
  have hx_neg : Tendsto (fun x : ‚Ñù => -x) atTop atBot :=
    (tendsto_neg_atBot_iff).mpr tendsto_id
  have h_exp : Tendsto (fun x => Real.exp (-x)) atTop (ùìù 0) :=
    Real.tendsto_exp_atBot.comp hx_neg
  have h_cont : ContinuousAt (fun r : ‚Ñù => (1 : ‚Ñù) / (1 + r)) 0 :=
    (continuousAt_const.div (continuousAt_const.add continuousAt_id) (by norm_num))
  have h_comp :
      Tendsto (fun x => (1 : ‚Ñù) / (1 + Real.exp (-x))) atTop (ùìù ((1 : ‚Ñù) / (1 + 0))) :=
    h_cont.tendsto.comp h_exp
  unfold logisticProb
  simpa [Real.exp_zero] using h_comp

/-- As `x ‚Üí -‚àû`, `logisticProb x ‚Üí 0`. -/
lemma logisticProb_tendsto_atBot :
    Tendsto logisticProb atBot (ùìù (0 : ‚Ñù)) := by
  -- 0 ‚â§ logistic ‚â§ exp, and exp x ‚Üí 0 as x‚Üí-‚àû
  have h_le_exp : ‚àÄ x : ‚Ñù, logisticProb x ‚â§ Real.exp x := by
    intro x
    unfold logisticProb
    have hxpos : 0 < Real.exp (-x) := Real.exp_pos _
    have hz_le : Real.exp (-x) ‚â§ 1 + Real.exp (-x) := by linarith
    have : (1 : ‚Ñù) / (1 + Real.exp (-x)) ‚â§ (1 : ‚Ñù) / Real.exp (-x) :=
      one_div_le_one_div_of_le hxpos hz_le
    simpa [one_div, Real.exp_neg] using this
  refine
    tendsto_of_tendsto_of_tendsto_of_le_of_le
      (tendsto_const_nhds) (Real.tendsto_exp_atBot)
      (fun x => logisticProb_nonneg x)
      (fun x => h_le_exp x)

/-- As `T ‚Üí 0+`, if `c > 0` then `c/T ‚Üí +‚àû`. -/
lemma tendsto_c_div_atTop_of_pos {c : ‚Ñù} (hc : 0 < c) :
    Tendsto (fun T : ‚Ñù => c / T) (ùìù[>] (0 : ‚Ñù)) atTop := by
  have h_inv : Tendsto (fun T : ‚Ñù => T‚Åª¬π) (ùìù[>] (0 : ‚Ñù)) atTop :=
    tendsto_inv_nhdsGT_zero
  have h_mul := tendsto_mul_const_atTop_atTop_of_pos hc
  simpa [div_eq_mul_inv] using (h_mul.comp h_inv)

/-- As `T ‚Üí 0+`, if `c < 0` then `c/T ‚Üí -‚àû`. -/
lemma tendsto_c_div_atBot_of_neg {c : ‚Ñù} (hc : c < 0) :
    Tendsto (fun T : ‚Ñù => c / T) (ùìù[>] (0 : ‚Ñù)) atBot := by
  have h_inv : Tendsto (fun T : ‚Ñù => T‚Åª¬π) (ùìù[>] (0 : ‚Ñù)) atTop :=
    tendsto_inv_nhdsGT_zero
  have h_mul := tendsto_mul_const_atTop_atBot_of_neg hc
  simpa [div_eq_mul_inv] using (h_mul.comp h_inv)

/-- As `T ‚Üí 0+`, if `c > 0` then `logisticProb (c/T) ‚Üí 1`. -/
lemma tendsto_logistic_scaled_of_pos {c : ‚Ñù} (hc : 0 < c) :
    Tendsto (fun T : ‚Ñù => logisticProb (c / T)) (ùìù[>] (0 : ‚Ñù)) (ùìù (1 : ‚Ñù)) :=
  logisticProb_tendsto_atTop.comp (tendsto_c_div_atTop_of_pos hc)

/-- As `T ‚Üí 0+`, if `c < 0` then `logisticProb (c/T) ‚Üí 0`. -/
lemma tendsto_logistic_scaled_of_neg {c : ‚Ñù} (hc : c < 0) :
    Tendsto (fun T : ‚Ñù => logisticProb (c / T)) (ùìù[>] (0 : ‚Ñù)) (ùìù (0 : ‚Ñù)) :=
  logisticProb_tendsto_atBot.comp (tendsto_c_div_atBot_of_neg hc)

/-- As `T ‚Üí 0+`, if `c = 0` then `logisticProb (c/T)` is constantly `1/2`. -/
lemma tendsto_logistic_scaled_of_eq_zero {c : ‚Ñù} (hc : c = 0) :
    Tendsto (fun T : ‚Ñù => logisticProb (c / T)) (ùìù[>] (0 : ‚Ñù)) (ùìù ((1 : ‚Ñù) / 2)) := by
  have : (fun T : ‚Ñù => logisticProb (c / T)) =·∂†[ùìù[>] (0 : ‚Ñù)] fun _ => 1 / 2 := by
    filter_upwards [self_mem_nhdsWithin] with T _
    simp [logisticProb, hc, Real.exp_zero, one_add_one_eq_two]
  exact (tendsto_congr' this).mpr tendsto_const_nhds

/-- As `T ‚Üí 0+`, `logisticProb (c / T)` tends to `1` if `c > 0`, to `0` if `c < 0`,
and to `1/2` if `c = 0`. -/
lemma tendsto_logistic_scaled
    (c : ‚Ñù) :
    Tendsto (fun T : ‚Ñù => logisticProb (c / T)) (nhdsWithin 0 (Set.Ioi 0))
      (ùìù (if 0 < c then 1 else if c < 0 then 0 else 1/2)) := by
  by_cases hcpos : 0 < c
  ¬∑ simpa [hcpos] using (tendsto_logistic_scaled_of_pos (c:=c) hcpos)
  ¬∑ by_cases hcneg : c < 0
    ¬∑ have := tendsto_logistic_scaled_of_neg (c:=c) hcneg
      simpa [hcpos, hcneg] using this
    ¬∑ have hc0 : c = 0 := le_antisymm (le_of_not_gt hcpos) (le_of_not_gt hcneg)
      simpa [hcpos, hcneg, hc0] using (tendsto_logistic_scaled_of_eq_zero (c:=c) hc0)

/-- On ‚Ñù‚â•0: as `b ‚Üí ‚àû`, `logisticProb (c * b) ‚Üí 1/0/1/2` depending on the sign of `c`. -/
lemma tendsto_logistic_const_mul_coeNNReal
    (c : ‚Ñù) :
    Tendsto (fun b : ‚Ñù‚â•0 => logisticProb (c * (b : ‚Ñù))) atTop
      (ùìù (if 0 < c then 1 else if c < 0 then 0 else 1/2)) := by
  have h_coe : Tendsto (fun b : ‚Ñù‚â•0 => (b : ‚Ñù)) atTop atTop := by
    refine (Filter.tendsto_atTop_atTop).2 ?_
    intro M
    refine ‚ü®‚ü®max 0 (M + 1), by have : 0 ‚â§ max 0 (M + 1) := le_max_left _ _; exact this‚ü©, ?_‚ü©
    intro b hb
    have hBR : (max 0 (M + 1) : ‚Ñù) ‚â§ (b : ‚Ñù) := by exact_mod_cast hb
    have hM1 : (M + 1 : ‚Ñù) ‚â§ (b : ‚Ñù) := le_trans (le_max_right _ _) hBR
    have : (M : ‚Ñù) ‚â§ (b : ‚Ñù) := by linarith
    exact this
  by_cases hcpos : 0 < c
  ¬∑
    have hmul := tendsto_mul_const_atTop_atTop_of_pos (c:=c) hcpos
    simpa [hcpos, Function.comp] using
      logisticProb_tendsto_atTop.comp (hmul.comp h_coe)
  ¬∑ by_cases hcneg : c < 0
    ¬∑
      have hmul := tendsto_mul_const_atTop_atBot_of_neg (c:=c) hcneg
      simpa [hcpos, hcneg, Function.comp] using
        logisticProb_tendsto_atBot.comp (hmul.comp h_coe)
    ¬∑
      have hc0 : c = 0 := le_antisymm (le_of_not_gt hcpos) (le_of_not_gt hcneg)
      have hconst :
          (fun b : ‚Ñù‚â•0 => logisticProb (c * (b : ‚Ñù))) = fun _ => (1/2 : ‚Ñù) := by
        funext b; simp [hc0, logisticProb, Real.exp_zero, one_add_one_eq_two]
      aesop

omit [DecidableEq U] [Fintype U] [Nonempty U] in
/-- Real-valued probability limit P(T) for our model as T ‚Üí 0+. -/
private lemma tendsto_probPos_at_zero
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (_ : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U) :
    let L : R := (s.net p u) - (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)
    Tendsto (fun T : ‚Ñù => probPos (NN:=NN) f p ‚ü®Real.toNNReal T‚ü© s u)
      (nhdsWithin 0 (Set.Ioi 0))
      (ùìù (let Œ∫ := scale (NN:=NN) (f:=f); let c := (Œ∫ / kB) * (f L);
          if 0 < c then 1 else if c < 0 then 0 else 1/2)) := by
  intro L
  have h_event :
      (fun T : ‚Ñù => probPos (NN:=NN) f p ‚ü®Real.toNNReal T‚ü© s u)
        =·∂†[nhdsWithin 0 (Set.Ioi 0)]
      (fun T : ‚Ñù =>
        logisticProb (((scale (NN:=NN) (f:=f)) / kB) * (f L) / T)) := by
    filter_upwards [self_mem_nhdsWithin] with T hTpos
    have hT0 : 0 ‚â§ T := le_of_lt hTpos
    have : (Œ≤ ‚ü®Real.toNNReal T‚ü© : ‚Ñù) = 1 / (kB * T) := by
      simp [Temperature.Œ≤, Temperature.toReal, Real.toNNReal_of_nonneg hT0, one_div]
    unfold probPos
    simp [this, logisticProb, one_div, mul_comm, mul_left_comm, mul_assoc, div_eq_mul_inv]
    aesop
  have hlim :
      Tendsto (fun T : ‚Ñù =>
        logisticProb (((scale (NN:=NN) (f:=f)) / kB) * (f L) / T))
        (nhdsWithin 0 (Set.Ioi 0))
        (ùìù (let Œ∫ := scale (NN:=NN) (f:=f); let c := (Œ∫ / kB) * (f L);
             if 0 < c then 1 else if c < 0 then 0 else 1/2)) :=
    tendsto_logistic_scaled _
  exact (tendsto_congr' h_event).mpr hlim

/- Simple ENNReal evaluation lemmas for the Gibbs one-step with Bernoulli bind. -/
namespace PMF

variable {Œ± : Type}

@[simp]
lemma bernoulli_bind_pure_apply_left_of_ne
    {p : ‚Ñù‚â•0‚àû} (hp : p ‚â§ 1) {x y : Œ±} (hxy : x ‚â† y) :
    ((PMF.bernoulli p hp) >>= fun b => if b then PMF.pure x else PMF.pure y) x = p := by
  classical
  change (PMF.bind (PMF.bernoulli p hp) (fun b => if b then PMF.pure x else PMF.pure y)) x = p
  rw [PMF.bind_apply]
  simp only [PMF.bernoulli_apply, PMF.pure_apply, tsum_fintype]
  have : Finset.univ = ({false, true} : Finset Bool) := by
    ext b; simp
  rw [this, Finset.sum_pair (by simp : false ‚â† true)]
  simp only [Bool.cond_false, Bool.cond_true]
  simp [hxy, if_neg hxy.symm]

@[simp]
lemma bernoulli_bind_pure_apply_other
    {p : ‚Ñù‚â•0‚àû} (hp : p ‚â§ 1) {x y z : Œ±} (hx : z ‚â† x) (hy : z ‚â† y) :
    ((PMF.bernoulli p hp) >>= fun b => if b then PMF.pure x else PMF.pure y) z = 0 := by
  classical
  change (PMF.bind (PMF.bernoulli p hp) (fun b => if b then PMF.pure x else PMF.pure y)) z = 0
  rw [PMF.bind_apply]
  simp only [PMF.bernoulli_apply, PMF.pure_apply, tsum_fintype]
  have : Finset.univ = ({false, true} : Finset Bool) := by
    ext b; simp
  rw [this, Finset.sum_pair (by simp : false ‚â† true)]
  simp only [Bool.cond_false, Bool.cond_true]
  simp [hx, hy, if_neg hx.symm, if_neg hy.symm]

variable {Œ± : Type} [DecidableEq Œ±]

@[simp]
lemma bernoulli_bind_pure_apply_right_of_ne
    {p : ‚Ñù‚â•0‚àû} (hp : p ‚â§ 1) {x y : Œ±} (hxy : x ‚â† y) :
    ((PMF.bernoulli p hp) >>= fun b => if b then PMF.pure x else PMF.pure y) y = (1 - p) := by
  classical
  change (PMF.bind (PMF.bernoulli p hp) (fun b => if b then PMF.pure x else PMF.pure y)) y = (1 - p)
  rw [PMF.bind_apply]
  simp only [PMF.bernoulli_apply, PMF.pure_apply, tsum_fintype]
  have : Finset.univ = ({false, true} : Finset Bool) := by
    ext b; simp
  rw [this, Finset.sum_pair (by simp : false ‚â† true)]
  simp only [Bool.cond_false, Bool.cond_true]
  simp [hxy, if_neg hxy]
  aesop

end PMF
open PMF
omit [Fintype U] [Nonempty U] in
/-- Pointwise evaluation at `updPos`: exact (not just eventual) equality. -/
private lemma gibbsUpdate_apply_updPos
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù]
    (f : F) (p : Params NN) (T : Temperature) (s : NN.State) (u : U) :
    (gibbsUpdate (NN:=NN) f p T s u) (updPos (s:=s) (u:=u))
      = ENNReal.ofReal (probPos (NN:=NN) f p T s u) := by
  classical
  unfold gibbsUpdate
  set pPos := probPos (NN:=NN) f p T s u
  set pPosE := ENNReal.ofReal pPos
  have h_le : pPosE ‚â§ 1 := by
    simpa [pPosE] using probPos_le_one (NN:=NN) f p T s u
  have hne := updPos_ne_updNeg (s:=s) (u:=u)
  simp [PMF.bernoulli_bind_pure_apply_left_of_ne (Œ±:=NN.State) h_le hne, pPosE, pPos]

omit [Fintype U] [Nonempty U] in
/-- Pointwise evaluation at `updNeg`: exact (not just eventual) equality. -/
private lemma gibbsUpdate_apply_updNeg
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù]
    (f : F) (p : Params NN) (T : Temperature) (s : NN.State) (u : U) :
    (gibbsUpdate (NN:=NN) f p T s u) (updNeg (s:=s) (u:=u))
      = ENNReal.ofReal (1 - probPos (NN:=NN) f p T s u) := by
  classical
  unfold gibbsUpdate
  set pPos := probPos (NN:=NN) f p T s u
  set pPosE := ENNReal.ofReal pPos
  have h_le : pPosE ‚â§ 1 := by
    simpa [pPosE] using probPos_le_one (NN:=NN) f p T s u
  have hne := updPos_ne_updNeg (s:=s) (u:=u)
  have : ((PMF.bernoulli pPosE h_le) >>= fun b => if b then PMF.pure (updPos (s:=s) (u:=u)) else PMF.pure (updNeg (s:=s) (u:=u))) (updNeg (s:=s) (u:=u))
      = (1 - pPosE) := PMF.bernoulli_bind_pure_apply_right_of_ne (Œ±:=NN.State) h_le hne
  rw [this]
  have hpos_nonneg : 0 ‚â§ pPos := probPos_nonneg (NN:=NN) f p T s u
  have hpos_le_one : pPos ‚â§ 1 := probPos_le_one (NN:=NN) f p T s u
  have h_eq : (1 : ‚Ñù‚â•0‚àû) - pPosE = ENNReal.ofReal (1 - pPos) := by
    simp_rw [pPosE]
    rw [‚Üê ENNReal.ofReal_one]
    rw [ENNReal.ofReal_sub 1 hpos_nonneg]
  rw [h_eq]

omit [Fintype U] [Nonempty U] in
/-- Eventual equality rewriting Gibbs mass at updPos along Œ≤ ‚Üí ‚àû to ENNReal.ofReal (probPos at T). -/
private lemma eventually_eval_updPos_eq_ofReal_probPos
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù]
    (f : F) (p : Params NN) (s : NN.State) (u : U) :
    (fun b : ‚Ñù‚â•0 => (gibbsUpdate (NN:=NN) f p (Temperature.ofŒ≤ b) s u) (updPos (s:=s) (u:=u)))
      =·∂†[atTop]
    (fun b : ‚Ñù‚â•0 => ENNReal.ofReal (probPos (NN:=NN) f p (Temperature.ofŒ≤ b) s u)) := by
  refine Filter.Eventually.of_forall ?_
  intro b; simp [gibbsUpdate_apply_updPos]

omit [Fintype U] [Nonempty U] in
/-- Eventual equality rewriting Gibbs mass at updNeg along Œ≤ ‚Üí ‚àû to ENNReal.ofReal (1 - probPos). -/
private lemma eventually_eval_updNeg_eq_ofReal_one_sub_probPos
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù]
    (f : F) (p : Params NN) (s : NN.State) (u : U) :
    (fun b : ‚Ñù‚â•0 => (gibbsUpdate (NN:=NN) f p (Temperature.ofŒ≤ b) s u) (updNeg (s:=s) (u:=u)))
      =·∂†[atTop]
    (fun b : ‚Ñù‚â•0 => ENNReal.ofReal (1 - probPos (NN:=NN) f p (Temperature.ofŒ≤ b) s u)) := by
  refine Filter.Eventually.of_forall ?_
  intro b; simp [gibbsUpdate_apply_updNeg]

omit [Fintype U] [Nonempty U] in
/-- Target evaluation: the zero-temperature PMF mass at `updPos` as an ENNReal.ofReal
    piecewise {1,0,1/2} driven by the sign of `((scale f)/kB) * f L`. -/
private lemma zeroTemp_target_updPos_as_ofReal_sign
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U) :
    let net := s.net p u
    let Œ∏ := (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)
    (zeroTempLimitPMF (NN:=NN) p s u) (updPos (s:=s) (u:=u)) =
      ENNReal.ofReal
        (if 0 < ((scale (NN:=NN) (f:=f)) / kB) * (f (net - Œ∏))
         then 1 else if ((scale (NN:=NN) (f:=f)) / kB) * (f (net - Œ∏)) < 0 then 0 else (1/2 : ‚Ñù)) := by
  classical
  intro net Œ∏
  by_cases hpos : Œ∏ < net
  ¬∑ -- positive local field: pure updPos, RHS selects 1 branch
    have hLpos : 0 < (net - Œ∏) := sub_pos.mpr hpos
    have hfpos : 0 < f (net - Œ∏) := map_pos_of_pos (R:=R) (f:=f) hf hLpos
    have hŒ∫pos : 0 < ((scale (NN:=NN) (f:=f)) / kB) :=
      div_pos (scale_pos (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f) hf) kB_pos
    have hprodpos : 0 < ((scale (NN:=NN) (f:=f)) / kB) * (f (net - Œ∏)) :=
      mul_pos hŒ∫pos hfpos
    have hne := updPos_ne_updNeg (s:=s) (u:=u)
    simp only [zeroTempLimitPMF, net, Œ∏, hpos, not_lt.mpr hpos.le, PMF.pure_apply,
      hne, dite_eq_ite, if_true, ENNReal.ofReal_one]
    simp [hprodpos]
    aesop
  ¬∑ by_cases hneg : net < Œ∏
    ¬∑ -- negative local field: pure updNeg at updPos gives 0, RHS selects 0 branch
      have hLneg : (net - Œ∏) < 0 := sub_lt_zero.mpr hneg
      have hfneg : f (net - Œ∏) < 0 := map_neg_of_neg (R:=R) (f:=f) hf hLneg
      have hŒ∫pos : 0 < ((scale (NN:=NN) (f:=f)) / kB) :=
        div_pos (scale_pos (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f) hf) kB_pos
      have hprodneg : ((scale (NN:=NN) (f:=f)) / kB) * (f (net - Œ∏)) < 0 :=
        mul_neg_of_pos_of_neg hŒ∫pos hfneg
      have hne := updPos_ne_updNeg (s:=s) (u:=u)
      simp only [zeroTempLimitPMF, net, Œ∏, hneg, not_lt.mpr hneg.le, PMF.pure_apply,
        hne, dite_eq_ite, if_false, if_true, ENNReal.ofReal_zero]
      rw [@ENNReal.zero_eq_ofReal]
      have hprodneg' :
          ((scale (NN:=NN) (f:=f)) / kB) * ((f net) - (f Œ∏)) < 0 := by
        simpa [map_sub f] using hprodneg
      simpa using
        (piecewise01half_le_zero_of_neg
          (x := ((scale (NN:=NN) (f:=f)) / kB) * ((f net) - (f Œ∏)))) hprodneg'
    ¬∑ -- tie: 1/2 mixture, RHS selects 1/2 branch
      have h_eq : net = Œ∏ := le_antisymm (le_of_not_gt hpos) (le_of_not_gt hneg)
      have hf0 : f (net - Œ∏) = 0 := by simp [h_eq, map_zero f]
      have hne := updPos_ne_updNeg (s:=s) (u:=u)
      simp [zeroTempLimitPMF, net, Œ∏, hpos, hneg, hf0, hne]

omit [Fintype U] [Nonempty U] in
/-- Target evaluation: the zero-temperature PMF mass at `updNeg` as ENNReal.ofReal
    of one minus the same 1/0/1/2 piecewise expression. -/
private lemma zeroTemp_target_updNeg_as_ofReal_one_sub_sign
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U) :
    let net := s.net p u
    let Œ∏ := (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)
    (zeroTempLimitPMF (NN:=NN) p s u) (updNeg (s:=s) (u:=u)) =
      ENNReal.ofReal
        (1 - (if 0 < ((scale (NN:=NN) (f:=f)) / kB) * (f (net - Œ∏))
              then 1 else if ((scale (NN:=NN) (f:=f)) / kB) * (f (net - Œ∏)) < 0 then 0 else (1/2 : ‚Ñù))) := by
  classical
  intro net Œ∏
  by_cases hpos : Œ∏ < net
  ¬∑ have hLpos : 0 < (net - Œ∏) := sub_pos.mpr hpos
    have hfpos : 0 < f (net - Œ∏) := map_pos_of_pos (R:=R) (f:=f) hf hLpos
    have hŒ∫pos : 0 < ((scale (NN:=NN) (f:=f)) / kB) :=
      div_pos (scale_pos (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f) hf) kB_pos
    have hprodpos : 0 < ((scale (NN:=NN) (f:=f)) / kB) * (f (net - Œ∏)) :=
      mul_pos hŒ∫pos hfpos
    have hne := updPos_ne_updNeg (s:=s) (u:=u)
    simp [zeroTempLimitPMF, net, Œ∏, hpos, not_lt.mpr hpos.le, hprodpos, PMF.pure_apply, hne]
    aesop
  ¬∑ by_cases hneg : net < Œ∏
    ¬∑ have hLneg : (net - Œ∏) < 0 := sub_lt_zero.mpr hneg
      have hfneg : f (net - Œ∏) < 0 := map_neg_of_neg (R:=R) (f:=f) hf hLneg
      have hŒ∫pos : 0 < ((scale (NN:=NN) (f:=f)) / kB) :=
        div_pos (scale_pos (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f) hf) kB_pos
      have hprodneg : ((scale (NN:=NN) (f:=f)) / kB) * (f (net - Œ∏)) < 0 :=
        mul_neg_of_pos_of_neg hŒ∫pos hfneg
      have hne := updPos_ne_updNeg (s:=s) (u:=u)
      have hprodneg' :
          ((scale (NN:=NN) (f:=f)) / kB) * ((f net) - (f Œ∏)) < 0 := by
        simpa [map_sub f] using hprodneg
      have hnotpos' :
          ¬¨ 0 < ((scale (NN:=NN) (f:=f)) / kB) * ((f net) - (f Œ∏)) :=
        not_lt.mpr hprodneg'.le
      simp [zeroTempLimitPMF, net, Œ∏, hneg, not_lt.mpr hneg.le, PMF.pure_apply,
            hprodneg', hnotpos', one_div]
    ¬∑ -- tie branch: 1 - ofReal(1/2) = ofReal (1 - 1/2)
      have h_eq : net = Œ∏ := le_antisymm (le_of_not_gt hpos) (le_of_not_gt hneg)
      have hf0 : f (net - Œ∏) = 0 := by simp [h_eq, map_zero f]
      have hne := updPos_ne_updNeg (s:=s) (u:=u)
      let pHalf : ‚Ñù‚â•0‚àû := ENNReal.ofReal (1 / 2 : ‚Ñù)
      have hp : pHalf ‚â§ 1 := by
        simpa [pHalf] using
          (ENNReal.ofReal_le_one.mpr (by norm_num : (1 / 2 : ‚Ñù) ‚â§ 1))
      have hbind :
        ((PMF.bernoulli pHalf hp) >>= fun b =>
            if b then PMF.pure (updPos (s:=s) (u:=u))
                 else PMF.pure (updNeg (s:=s) (u:=u)))
          (updNeg (s:=s) (u:=u)) = 1 - pHalf :=
        PMF.bernoulli_bind_pure_apply_right_of_ne (Œ±:=NN.State) hp hne
      have hle‚ÇÅ : (1 / 2 : ‚Ñù) ‚â§ 1 := by norm_num
      have hnonneg : (0 : ‚Ñù) ‚â§ (1 / 2 : ‚Ñù) := by norm_num
      have hsub :
          (1 : ‚Ñù‚â•0‚àû) - ENNReal.ofReal (1 / 2 : ‚Ñù) =
            ENNReal.ofReal (1 - (1 / 2 : ‚Ñù)) := by
        have h := ENNReal.ofReal_sub
          (p := (1 : ‚Ñù)) (q := (1 / 2 : ‚Ñù)) (by norm_num : (0 : ‚Ñù) ‚â§ (1 / 2 : ‚Ñù))
        simpa [ENNReal.ofReal_one, one_div] using h.symm
      have hbind' :
          ((PMF.bernoulli pHalf hp) >>= fun b =>
              if b then PMF.pure (updPos (s:=s) (u:=u))
                   else PMF.pure (updNeg (s:=s) (u:=u)))
            (updNeg (s:=s) (u:=u))
          = (1 - ENNReal.ofReal (1 / 2 : ‚Ñù)) := by
        simpa [pHalf] using hbind
      simp [zeroTempLimitPMF, net, Œ∏, hpos, hneg, hf0, hne]
      aesop

omit [DecidableEq U] [Fintype U] [Nonempty U] in
/-- Real-valued limit along `Œ≤ (ofŒ≤ b) = b`: `probPos` tends to 1/0/1/2 by the sign of `c0`. -/
private lemma tendsto_probPos_along_ofŒ≤_to_piecewise
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (p : Params NN) (s : NN.State) (u : U) :
    let L := (s.net p u) - (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)
    let c0 : ‚Ñù := (scale (NN:=NN) (f:=f)) * (f L)
    Tendsto (fun b : ‚Ñù‚â•0 => probPos (NN:=NN) f p (Temperature.ofŒ≤ b) s u)
      atTop
      (ùìù (if 0 < c0 then 1 else if c0 < 0 then 0 else 1/2)) := by
  intro L c0
  have hŒ≤ : ‚àÄ b, (Œ≤ (Temperature.ofŒ≤ b) : ‚Ñù) = b := by intro b; simp
  have h_form :
      ‚àÄ b, probPos (NN:=NN) f p (Temperature.ofŒ≤ b) s u
            = logisticProb (c0 * (b : ‚Ñù)) := by
    intro b; unfold probPos; simp [hŒ≤ b, L, c0, mul_comm, mul_left_comm, mul_assoc, logisticProb]
  simpa [h_form] using tendsto_logistic_const_mul_coeNNReal c0

omit [Fintype U] [Nonempty U] in
/-- Convergence on `updPos`: short proof using the split helpers. -/
lemma gibbs_update_tends_to_zero_temp_limit_apply_updPos
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U) :
    Tendsto (fun b : ‚Ñù‚â•0 =>
      (gibbsUpdate (NN:=NN) f p (Temperature.ofŒ≤ b) s u) (updPos (s:=s) (u:=u)))
      atTop (ùìù ((zeroTempLimitPMF (NN:=NN) p s u) (updPos (s:=s) (u:=u)))) := by
  classical
  have h_target := zeroTemp_target_updPos_as_ofReal_sign (NN:=NN) f hf p s u
  have hev := eventually_eval_updPos_eq_ofReal_probPos (NN:=NN) f p s u
  set net := s.net p u
  set Œ∏ := (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)
  set L : R := net - Œ∏
  set c0 : ‚Ñù := (scale (NN:=NN) (f:=f)) * (f L)
  have h_real := tendsto_probPos_along_ofŒ≤_to_piecewise (NN:=NN) f p s u
  have h_rewrite := sign_piecewise_rewrite_with_c0 (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f) L
  have hlim := ENNReal.tendsto_ofReal (by simpa [L, c0, h_rewrite] using h_real)
  have h := (tendsto_congr' hev).mpr hlim
  have h' : Tendsto (fun b : ‚Ñù‚â•0 =>
      (gibbsUpdate (NN:=NN) f p (Temperature.ofŒ≤ b) s u) (updPos (s:=s) (u:=u)))
      atTop (ùìù (ENNReal.ofReal
        (if 0 < ((scale (NN:=NN) (f:=f)) / kB) * (f (net - Œ∏))
         then 1 else if ((scale (NN:=NN) (f:=f)) / kB) * (f (net - Œ∏)) < 0 then 0 else (1/2 : ‚Ñù)))) := by
    aesop
  simpa [h_target, net, Œ∏] using h'

omit [Fintype U] [Nonempty U] in
/-- Convergence on `updNeg`: short proof using the split helpers. -/
lemma gibbs_update_tends_to_zero_temp_limit_apply_updNeg
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U) :
    Tendsto (fun b : ‚Ñù‚â•0 =>
      (gibbsUpdate (NN:=NN) f p (Temperature.ofŒ≤ b) s u) (updNeg (s:=s) (u:=u)))
      atTop (ùìù ((zeroTempLimitPMF (NN:=NN) p s u) (updNeg (s:=s) (u:=u)))) := by
  classical
  have h_target := zeroTemp_target_updNeg_as_ofReal_one_sub_sign (NN:=NN) f hf p s u
  have hev := eventually_eval_updNeg_eq_ofReal_one_sub_probPos (NN:=NN) f p s u
  set net := s.net p u
  set Œ∏ := (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)
  set L : R := net - Œ∏
  set c0 : ‚Ñù := (scale (NN:=NN) (f:=f)) * (f L)
  have h_real :=
    tendsto_probPos_along_ofŒ≤_to_piecewise (NN:=NN) f p s u
  have h_sub :
      Tendsto (fun b : ‚Ñù‚â•0 =>
        (1 : ‚Ñù) - probPos (NN:=NN) f p (Temperature.ofŒ≤ b) s u)
        atTop
        (ùìù (1 - (if 0 < c0 then 1 else if c0 < 0 then 0 else (1/2)))) :=
    tendsto_const_nhds.sub h_real
  have h_lift :
      Tendsto (fun b : ‚Ñù‚â•0 =>
        ENNReal.ofReal (1 - probPos (NN:=NN) f p (Temperature.ofŒ≤ b) s u))
        atTop
        (ùìù (ENNReal.ofReal (1 - (if 0 < c0 then 1 else if c0 < 0 then 0 else (1/2))))) :=
    ENNReal.tendsto_ofReal h_sub
  have h_rewrite :
      (if 0 < ((scale (NN:=NN) (f:=f)) / kB) * (f L) then 1
       else if ((scale (NN:=NN) (f:=f)) / kB) * (f L) < 0 then 0 else (1/2 : ‚Ñù))
        =
      (if 0 < c0 then 1 else if c0 < 0 then 0 else (1/2 : ‚Ñù)) := by
    simpa [c0, one_div] using
      sign_piecewise_rewrite_with_c0
        (R:=R) (U:=U) (œÉ:=œÉ) (NN:=NN) (f:=f) L
  have h_conv :
      Tendsto (fun b : ‚Ñù‚â•0 =>
        (gibbsUpdate (NN:=NN) f p (Temperature.ofŒ≤ b) s u) (updNeg (s:=s) (u:=u)))
        atTop
        (ùìù (ENNReal.ofReal
              (1 - (if 0 < ((scale (NN:=NN) (f:=f)) / kB) * (f L)
                     then 1 else if ((scale (NN:=NN) (f:=f)) / kB) * (f L) < 0
                                   then 0 else (1/2 : ‚Ñù))))) := by
    have := (tendsto_congr' hev).mpr h_lift
    aesop
  aesop

omit [Fintype U] [Nonempty U] in
/-- Convergence on any ‚Äúother‚Äù state (neither updPos nor updNeg). -/
lemma gibbs_update_tends_to_zero_temp_limit_apply_other
    {F} [FunLike F R ‚Ñù]
    (f : F)
    (p : Params NN) (s : NN.State) (u : U)
    {state : NN.State}
    (hpos : state ‚â† updPos (s:=s) (u:=u))
    (hneg : state ‚â† updNeg (s:=s) (u:=u)) :
    Tendsto (fun b : ‚Ñù‚â•0 =>
      (gibbsUpdate (NN:=NN) f p (Temperature.ofŒ≤ b) s u) state)
      atTop (ùìù ((zeroTempLimitPMF (NN:=NN) p s u) state)) := by
  classical
  set net := s.net p u
  set Œ∏ := (p.Œ∏ u).get (TwoStateNeuralNetwork.Œ∏0 (NN:=NN) u)
  have htarget0 :
      (zeroTempLimitPMF (NN:=NN) p s u) state = 0 := by
    by_cases hŒ∏net : Œ∏ < net
    ¬∑ simp [zeroTempLimitPMF, net, Œ∏, hŒ∏net, PMF.pure_apply, hpos]
    ¬∑ by_cases hnetŒ∏ : net < Œ∏
      ¬∑ simp [zeroTempLimitPMF, net, Œ∏, hŒ∏net, hnetŒ∏, PMF.pure_apply, hneg]
      ¬∑
        have hp : ENNReal.ofReal (1/2) ‚â§ (1 : ‚Ñù‚â•0‚àû) := by
          simpa using (ENNReal.ofReal_le_one.2 (by norm_num : (1/2 : ‚Ñù) ‚â§ 1))
        have hbind_zero :
          ((PMF.bernoulli (ENNReal.ofReal (1/2)) hp) >>= fun b =>
            if b then PMF.pure (updPos (s:=s) (u:=u)) else PMF.pure (updNeg (s:=s) (u:=u))) state = 0 :=
          PMF.bernoulli_bind_pure_apply_other (Œ±:=NN.State) hp hpos hneg
        simpa [zeroTempLimitPMF, net, Œ∏, hŒ∏net, hnetŒ∏] using hbind_zero
  have hev :
      (fun b : ‚Ñù‚â•0 =>
        (gibbsUpdate (NN:=NN) f p (Temperature.ofŒ≤ b) s u) state)
      =·∂†[atTop] (fun _ => (0 : ‚Ñù‚â•0‚àû)) := by
    refine Filter.Eventually.of_forall ?_
    intro b
    simp [gibbsUpdate, PMF.bind_apply, tsum_fintype, PMF.pure_apply, hpos, hneg]
  have : Tendsto (fun b : ‚Ñù‚â•0 =>
    (gibbsUpdate (NN:=NN) f p (Temperature.ofŒ≤ b) s u) state) atTop (ùìù 0) :=
    (tendsto_congr' hev).mpr tendsto_const_nhds
  simpa [htarget0] using this

omit [Fintype U] [Nonempty U] in
/-- **Theorem** Pointwise convergence of the one‚Äìsite Gibbs PMF to the zero-temperature limit PMF,
for every state. This wraps the three evaluation lemmas into a single statement. -/
theorem gibbs_update_tends_to_zero_temp_limit
    {F} [FunLike F R ‚Ñù] [RingHomClass F R ‚Ñù] [OrderHomClass F R ‚Ñù]
    (f : F) (hf : Function.Injective f)
    (p : Params NN) (s : NN.State) (u : U) :
    ‚àÄ state : NN.State,
      Tendsto (fun b : ‚Ñù‚â•0 =>
        (gibbsUpdate (NN:=NN) f p (Temperature.ofŒ≤ b) s u) state)
        atTop (ùìù ((zeroTempLimitPMF (NN:=NN) p s u) state)) := by
  classical
  intro state
  by_cases hpos : state = updPos (s:=s) (u:=u)
  ¬∑ subst hpos
    exact gibbs_update_tends_to_zero_temp_limit_apply_updPos
            (NN:=NN) f hf p s u
  ¬∑ by_cases hneg : state = updNeg (s:=s) (u:=u)
    ¬∑ subst hneg
      exact gibbs_update_tends_to_zero_temp_limit_apply_updNeg
              (NN:=NN) f hf p s u
    ¬∑ exact gibbs_update_tends_to_zero_temp_limit_apply_other
              (NN:=NN) f p s u (by simpa using hpos) (by simpa using hneg)

end Convergence
end TwoState
